{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5b410e-ed58-40c6-8476-e6923f910fad",
   "metadata": {},
   "source": [
    "# Essential Functions in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba6bb6b6-4b7e-441c-9a1a-7ac73325a29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec9357f-cdaa-45ac-a1c7-82b357f6ac3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(img):\n",
    "    cv2.imshow('', img)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35281bd9-622f-4aad-9495-1a2a5d935c94",
   "metadata": {},
   "source": [
    "## Resize a image -- DownScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a85e93c-0667-41ec-83ef-c0e7ba803440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downScale_img(img, downScale=7):\n",
    "    img = cv2.imread(img)\n",
    "\n",
    "    width = img.shape[1]\n",
    "    height = img.shape[0]\n",
    "\n",
    "    width = width // downScale\n",
    "    height = height // downScale\n",
    "    dims = (width, height)\n",
    "\n",
    "    img = cv2.resize(img, dims)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ca00a7-fe4b-46e1-95bf-79f630c12cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = downScale_img(r\"./images/full_mammography.jpg\", )\n",
    "# cv2.imshow('Full Mammography resize',img1)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee57bb-d7c0-46e6-a84a-0a4cf197d894",
   "metadata": {},
   "source": [
    "## Blur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28bf2db6-ebb1-40ef-a4de-8fc75c79da0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blur_img(img, ksize=9):\n",
    "    ks = (ksize, ksize)\n",
    "    blur = cv2.GaussianBlur(img, ks, cv2.BORDER_DEFAULT)\n",
    "    return blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82417022-08b8-48a3-a58f-34164d7f2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur1 = blur_img(img1, ksize=5)\n",
    "# show_img(blur1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b72448f-a790-4e5d-b96d-f4dbb5a66218",
   "metadata": {},
   "source": [
    "## Canny -- Detect the edges\n",
    "\n",
    "cv2.Canny(image, T_lower, T_upper, aperture_size, L2Gradient)\n",
    "\n",
    "Where: \n",
    "\n",
    "    Image: Input image to which Canny filter will be applied\n",
    "    T_lower: Lower threshold value in Hysteresis Thresholding\n",
    "    T_upper: Upper threshold value in Hysteresis Thresholding\n",
    "    aperture_size: Aperture size of the Sobel filter.\n",
    "    L2Gradient: Boolean parameter used for more precision in calculating Edge Gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2b5311f-7fe8-4a47-b567-11994d08e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_img(img, l_th1, up_th2, ap_size=5):\n",
    "    cny = cv2.Canny(img, l_th1, up_th2, apertureSize=ap_size)\n",
    "    return cny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a3b292-9a47-4b88-9ea7-ebf71d7eea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cny1 = canny_img(blur1, 600, 700)\n",
    "# show_img(cny1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3acd2-9ea6-4f7d-828b-8880c2a39664",
   "metadata": {},
   "source": [
    "## breast patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afa3679-49d2-4f07-8e51-f7f01752807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_patch = cv2.imread(\"./images/patch_calc.jpeg\")\n",
    "blur_patch = blur_img(img_patch, ksize=11)\n",
    "patch_cny = canny_img(blur_patch, l_th1=200, up_th2=50, ap_size=5)\n",
    "\n",
    "k = 7\n",
    "kernel = (k,k)\n",
    "patch_dilated = cv2.dilate(patch_cny, kernel, iterations = 3)\n",
    "patch_erode = cv2.erode(patch_dilated, kernel, iterations = 3)\n",
    "# show_img(patch_erode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd09f2b1-753b-4e73-a914-707f81ce9303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final, th = cv2.threshold(img_patch, 150, 255, cv2.THRESH_BINARY)\n",
    "gray = cv2.cvtColor(img_patch, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "alpha = -100 # Contrast control (1.0-3.0)\n",
    "beta = -100 # Brightness control (0-100)\n",
    "\n",
    "adjusted = cv2.convertScaleAbs(gray, alpha=alpha, beta=beta)\n",
    "show_img(adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d8e9861-99d2-452b-b215-581c044800e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def funcBrightContrast(bright=0):\n",
    "#     bright = cv2.getTrackbarPos('bright', 'Life2Coding')\n",
    "#     contrast = cv2.getTrackbarPos('contrast', 'Life2Coding')\n",
    "\n",
    "#     effect = apply_brightness_contrast(img,bright,contrast)\n",
    "#     cv2.imshow('Effect', effect)\n",
    "\n",
    "# def apply_brightness_contrast(input_img, brightness = 255, contrast = 127):\n",
    "#     brightness = map(brightness, 0, 510, -255, 255)\n",
    "#     contrast = map(contrast, 0, 254, -127, 127)\n",
    "\n",
    "#     if brightness != 0:\n",
    "#         if brightness > 0:\n",
    "#             shadow = brightness\n",
    "#             highlight = 255\n",
    "#         else:\n",
    "#             shadow = 0\n",
    "#             highlight = 255 + brightness\n",
    "#         alpha_b = (highlight - shadow)/255\n",
    "#         gamma_b = shadow\n",
    "\n",
    "#         buf = cv2.addWeighted(input_img, alpha_b, input_img, 0, gamma_b)\n",
    "#     else:\n",
    "#         buf = input_img.copy()\n",
    "\n",
    "#     if contrast != 0:\n",
    "#         f = float(131 * (contrast + 127)) / (127 * (131 - contrast))\n",
    "#         alpha_c = f\n",
    "#         gamma_c = 127*(1-f)\n",
    "\n",
    "#         buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n",
    "\n",
    "#     cv2.putText(buf,'B:{},C:{}'.format(brightness,contrast),(10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "#     return buf\n",
    "\n",
    "# def map(x, in_min, in_max, out_min, out_max):\n",
    "#     return int((x-in_min) * (out_max-out_min) / (in_max-in_min) + out_min)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     original = img_patch\n",
    "#     img = original.copy()\n",
    "\n",
    "#     cv2.namedWindow('Life2Coding',1)\n",
    "\n",
    "#     bright = 255\n",
    "#     contrast = 127\n",
    "\n",
    "#     #Brightness value range -255 to 255\n",
    "#     #Contrast value range -127 to 127\n",
    "\n",
    "#     cv2.createTrackbar('bright', 'Life2Coding', bright, 2*255, funcBrightContrast)\n",
    "#     cv2.createTrackbar('contrast', 'Life2Coding', contrast, 2*127, funcBrightContrast)\n",
    "#     funcBrightContrast(0)\n",
    "#     cv2.imshow('Life2Coding', original)\n",
    "\n",
    "\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ed656-aad3-4596-a9c9-c33081554b8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
